{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML FINAL_Hyperparameter tuning1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/superspray/DeepRecommender/blob/master/ML_FINAL_Hyperparameter_tuning1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "AkRcRomIQjWK",
        "outputId": "5a564a30-e230-43c4-8009-7dc54108dbc5"
      },
      "source": [
        "!git clone https://github.com/superspray/study.git\r\n",
        "\r\n",
        "import numpy as np # linear algebra\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "import lightgbm as lgb\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\r\n",
        "from sklearn.svm import LinearSVC,SVC\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\r\n",
        "\r\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\r\n",
        "\r\n",
        "train_data=pd.read_csv('/content/study/train2.csv')#, encoding='latin_1')#, engine='python', error_bad_lines=False)\r\n",
        "#train_data = pd.read_csv('/content/Corona_NLP_train.csv', encoding='latin_1')\r\n",
        "\r\n",
        "test_data = pd.read_csv('/content/study/Corona_NLP_test.csv')\r\n",
        "train_data.columns=test_data.columns\r\n",
        "print('train data shape is :', train_data.shape)\r\n",
        "print('test data shape is :', test_data.shape)\r\n",
        "train_data.tail()\r\n",
        "\r\n",
        "#train_data.drop_duplicates(inplace= True)\r\n",
        "train_data=train_data.drop_duplicates()\r\n",
        "test_data.drop_duplicates(inplace=True)\r\n",
        "train_data=train_data[train_data.Sentiment.notnull()]\r\n",
        "#train_data = train_data[train_data['Sentiment'].notna()]\r\n",
        "#train_data = train_data[train_data['Sentiment'].notna()]\r\n",
        "\r\n",
        "print('train data shape is :', train_data.shape)\r\n",
        "print('test data shape is :', test_data.shape)\r\n",
        "train_data.tail()\r\n",
        "train_data.head()\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'study'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 90 (delta 33), reused 13 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (90/90), done.\n",
            "train data shape is : (82311, 6)\n",
            "test data shape is : (3798, 6)\n",
            "train data shape is : (41158, 6)\n",
            "test data shape is : (3798, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22249.0</td>\n",
              "      <td>67201.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23-03-2020</td>\n",
              "      <td>Donald J. Trump, I'm worried about the economi...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22250.0</td>\n",
              "      <td>67202.0</td>\n",
              "      <td>Cranberry Township\"</td>\n",
              "      <td>23-03-2020</td>\n",
              "      <td>Found my secret stash of #ToiletPaper for anyo...</td>\n",
              "      <td>Extremely Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>39928.0</td>\n",
              "      <td>84880.0</td>\n",
              "      <td>California_USA</td>\n",
              "      <td>09-04-2020</td>\n",
              "      <td>joined the growing list of distilleries produ...</td>\n",
              "      <td>Extremely Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>39929.0</td>\n",
              "      <td>84881.0</td>\n",
              "      <td>Worthing_England</td>\n",
              "      <td>09-04-2020</td>\n",
              "      <td>Spanish supermarket chains amp food distributo...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3799.0</td>\n",
              "      <td>48751.0</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UserName  ...           Sentiment\n",
              "0   22249.0  ...            Positive\n",
              "1   22250.0  ...  Extremely Positive\n",
              "2   39928.0  ...  Extremely Positive\n",
              "3   39929.0  ...            Negative\n",
              "4    3799.0  ...             Neutral\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vfW6iQnQkSX",
        "outputId": "2dfb76b9-fbf6-4ee2-e496-3438135bdade"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "import re\r\n",
        "from nltk.corpus import stopwords\r\n",
        "stopWords = stopwords.words('english')\r\n",
        "\r\n",
        "\r\n",
        "def clean(text):\r\n",
        "\r\n",
        "    #     remove urls\r\n",
        "    text = re.sub(r'http\\S+', \" \", str(text))\r\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\r\n",
        "    text = re.sub(r\"you'll\", \"you will\", text)\r\n",
        "    text = re.sub(r\"i'll\", \"i will\", text)\r\n",
        "    text = re.sub(r\"she'll\", \"she will\", text)\r\n",
        "    text = re.sub(r\"he'll\", \"he will\", text)\r\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\r\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\r\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\r\n",
        "    text = re.sub(r\"what's\", \"what is\", text)\r\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\r\n",
        "    text = re.sub(r\"there's\", \"there is\", text)\r\n",
        "    text = re.sub(r\"here's\", \"here is\", text)\r\n",
        "    text = re.sub(r\"who's\", \"who is\", text)\r\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\r\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\r\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\r\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\r\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\r\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\r\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\r\n",
        "    text = re.sub(r\"don't\", \"do not\", text)\r\n",
        "    text = re.sub(r\"shouldn't\", \"should not\", text)\r\n",
        "    text = re.sub(r\"n't\", \" not\", text)\r\n",
        "\r\n",
        "    #     remove mentions\r\n",
        "    text = re.sub(r'@\\w+',' ',text)\r\n",
        "\r\n",
        "    #     remove hastags\r\n",
        "    text = re.sub(r'#\\w+', ' ', text)\r\n",
        "\r\n",
        "    #     remove digits\r\n",
        "    text = re.sub(r'\\d+', ' ', text)\r\n",
        "\r\n",
        "    #     remove html tags\r\n",
        "    text = re.sub('r<.*?>',' ', text)\r\n",
        "    text = re.sub(r'[^(A-Za-z)]',r' ',text)\r\n",
        "    text = re.sub('[\\d]',r'',text)\r\n",
        "    text = re.sub('[()]',r'',text)\r\n",
        "    text = re.sub(r'(<.*?>)',r'',text)\r\n",
        "    text = re.sub(r'  ',' ',text)\r\n",
        "    #     remove stop words \r\n",
        "    text = text.split()\r\n",
        "    text = \" \".join([word.lower() for word in text if not word in stopWords])\r\n",
        "    \r\n",
        "    text = re.sub(r'  ',' ',text)\r\n",
        "    text= re.sub(r\"\\s+\",\" \",text).strip()\r\n",
        "\r\n",
        "    return text\r\n",
        "train_df=train_data.copy().dropna(subset=['OriginalTweet']) \r\n",
        "test_df=test_data.copy()\r\n",
        "train_df['OriginalTweet'] = train_df['OriginalTweet'].apply(lambda x: clean(x))\r\n",
        "test_df['OriginalTweet'] = test_df['OriginalTweet'].apply(lambda x: clean(x))\r\n",
        "train_df= train_df[train_df['OriginalTweet'].notna()]\r\n",
        "train_df= train_df[train_df['OriginalTweet']!='']\r\n",
        "train_df= train_df[train_df['OriginalTweet']!=' ']\r\n",
        "train_df= train_df[train_df['OriginalTweet']!='  ']\r\n",
        "test_df= test_df[test_df['OriginalTweet']!='']\r\n",
        "test_df= test_df[test_df['OriginalTweet']!='']\r\n",
        "\r\n",
        "print('train data shape is :', train_df.shape)\r\n",
        "print('test df shape is :', test_df.shape)\r\n",
        "\r\n",
        "train_df.head(10)\r\n",
        "\r\n",
        "\r\n",
        "df_train = train_df.iloc[:,4:].reset_index(drop=True)\r\n",
        "df_test = test_df.iloc[:,4:].reset_index(drop=True)\r\n",
        "\r\n",
        "l = {\"Neutral\":0, \"Positive\":1,\"Extremely Positive\":1,\"Negative\":-1, \"Extremely Negative\":-1 }\r\n",
        "\r\n",
        "df_train=df_train.replace({\"Sentiment\": l})\r\n",
        "df_test=df_test.replace({\"Sentiment\": l})\r\n",
        "df_train.head()\r\n",
        "y_train = df_train['Sentiment'].copy()\r\n",
        "y_test = df_test['Sentiment'].copy()\r\n",
        "X_text_train = df_train['OriginalTweet'].copy()\r\n",
        "X_text_test = df_test['OriginalTweet'].copy()\r\n",
        "X_test=X_text_test\r\n",
        "X_train=X_text_train\r\n",
        "\r\n",
        "X_train.shape, y_train.shape,X_test.shape, y_test.shape\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "import datetime\r\n",
        "### K-fold cross-validation using pipeline ###\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "import time\r\n",
        "from sklearn.base import TransformerMixin \r\n",
        "from sklearn.feature_selection import SelectKBest, chi2\r\n",
        "!pip install xgboost\r\n",
        "#%%time\r\n",
        "from xgboost import XGBClassifier\r\n",
        "\r\n",
        "ngram=(1,1)\r\n",
        "! pip install catboost\r\n",
        "from catboost import CatBoostClassifier,Pool\r\n",
        "# 시간 표시 함수\r\n",
        "\r\n",
        "def format_time(elapsed):\r\n",
        "\r\n",
        "    # 반올림\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    \r\n",
        "    # hh:mm:ss으로 형태 변경\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\r\n",
        "\r\n",
        "class DenseTransformer(TransformerMixin):\r\n",
        "\r\n",
        "    def fit(self, X, y=None, **fit_params):\r\n",
        "        return self\r\n",
        "\r\n",
        "    def transform(self, X, y=None, **fit_params):\r\n",
        "        return X.toarray()\r\n",
        "y_train.shape\r\n",
        "from sklearn.model_selection import StratifiedKFold\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "train data shape is : (41119, 6)\n",
            "test df shape is : (3796, 6)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/c1/c1c4707013f9e2f8a96899dd3a87f66c9167d6d776a6dc8fe7ec8678d446/catboost-0.24.3-cp36-none-manylinux1_x86_64.whl (66.3MB)\n",
            "\u001b[K     |████████████████████████████████| 66.3MB 63kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.24.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41119,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtnBHbxt53_V",
        "outputId": "70db794f-9f24-4be7-8e86-3e8840ae004c"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41119,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmBm2dTUTWNO",
        "outputId": "2de779e8-be6d-4641-9b0b-eb2bdaa892e8"
      },
      "source": [
        "### Grid search에 의한 초모수 결정 (SVM) ###\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.svm import SVC\r\n",
        "\r\n",
        "preproc = Pipeline([('tfidf',TfidfVectorizer(ngram_range = ngram,min_df = 5, max_df=0.6,lowercase = True)),('to_dense', DenseTransformer()),\r\n",
        "                      ('selec',SelectKBest(k=1000,score_func=chi2))])\r\n",
        "X_train1=preproc.fit_transform(X_train,y_train)\r\n",
        "X_test1=preproc.transform(X_test)\r\n",
        "\r\n",
        "param_range = [ 0.01, 0.1, 1.0, 10.0, 100.0]\r\n",
        "param_grid = [{'C': param_range, 'loss' :['hinge', 'squared_hinge']}]\r\n",
        "text_clf=LinearSVC(random_state=0, max_iter=5000)\r\n",
        "gs = GridSearchCV(estimator=text_clf, param_grid=param_grid,\r\n",
        "                scoring='accuracy', cv=5)\r\n",
        "gs = gs.fit(X_train1, y_train)\r\n",
        "print(gs.best_score_)\r\n",
        "print(gs.best_params_)\r\n",
        "\r\n",
        "clf = gs.best_estimator_\r\n",
        "clf.fit(X_train1, y_train)\r\n",
        "print(clf.score(X_train1,y_train))\r\n",
        "print('Model Training Accuracy w/o CV: %.3f' % clf.score(X_train1, y_train))\r\n",
        "print('Model Test Accuracy w/o CV: %.3f' % clf.score(X_test1, y_test))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8654881220747918\n",
            "{'C': 100.0, 'loss': 'hinge'}\n",
            "0.8766020574430312\n",
            "Model Training Accuracy w/o CV: 0.877\n",
            "Model Test Accuracy w/o CV: 0.848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([ 0.46330409,  0.50841064,  0.59043427,  0.51608262,  2.23697433,\n",
              "         0.75002451,  5.74730797,  2.97400594,  9.37727318, 25.65161605]),\n",
              " 'mean_score_time': array([0.0106554 , 0.01061983, 0.01065874, 0.01016645, 0.01036177,\n",
              "        0.01064129, 0.01075687, 0.01054611, 0.01083136, 0.01051126]),\n",
              " 'mean_test_score': array([0.65072097, 0.66677192, 0.72774158, 0.81286033, 0.84756456,\n",
              "        0.85476315, 0.86432079, 0.85663578, 0.86548812, 0.8569276 ]),\n",
              " 'param_C': masked_array(data=[0.01, 0.01, 0.1, 0.1, 1.0, 1.0, 10.0, 10.0, 100.0,\n",
              "                    100.0],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_loss': masked_array(data=['hinge', 'squared_hinge', 'hinge', 'squared_hinge',\n",
              "                    'hinge', 'squared_hinge', 'hinge', 'squared_hinge',\n",
              "                    'hinge', 'squared_hinge'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'C': 0.01, 'loss': 'hinge'},\n",
              "  {'C': 0.01, 'loss': 'squared_hinge'},\n",
              "  {'C': 0.1, 'loss': 'hinge'},\n",
              "  {'C': 0.1, 'loss': 'squared_hinge'},\n",
              "  {'C': 1.0, 'loss': 'hinge'},\n",
              "  {'C': 1.0, 'loss': 'squared_hinge'},\n",
              "  {'C': 10.0, 'loss': 'hinge'},\n",
              "  {'C': 10.0, 'loss': 'squared_hinge'},\n",
              "  {'C': 100.0, 'loss': 'hinge'},\n",
              "  {'C': 100.0, 'loss': 'squared_hinge'}],\n",
              " 'rank_test_score': array([10,  9,  8,  7,  6,  5,  2,  4,  1,  3], dtype=int32),\n",
              " 'split0_test_score': array([0.6589251 , 0.67570525, 0.72835603, 0.81201362, 0.84508755,\n",
              "        0.85384241, 0.86405642, 0.85530156, 0.86381323, 0.85481518]),\n",
              " 'split1_test_score': array([0.6563716 , 0.66974708, 0.72726167, 0.8125    , 0.84715467,\n",
              "        0.85347763, 0.86138132, 0.85432879, 0.86284047, 0.85517996]),\n",
              " 'split2_test_score': array([0.64494163, 0.66305934, 0.72215467, 0.81104086, 0.84302043,\n",
              "        0.85384241, 0.86247568, 0.85603113, 0.86344844, 0.85663911]),\n",
              " 'split3_test_score': array([0.64700875, 0.6641537 , 0.72701848, 0.81189202, 0.84776265,\n",
              "        0.85177529, 0.86284047, 0.8542072 , 0.86575875, 0.85517996]),\n",
              " 'split4_test_score': array([0.64635778, 0.66119421, 0.73391706, 0.81685516, 0.85479752,\n",
              "        0.86087803, 0.87085005, 0.86331023, 0.87157972, 0.86282379]),\n",
              " 'std_fit_time': array([0.01902602, 0.00601765, 0.06444058, 0.0048638 , 0.33509551,\n",
              "        0.01116926, 0.04595749, 0.1041464 , 0.09857001, 2.18771355]),\n",
              " 'std_score_time': array([0.0003411 , 0.00062849, 0.00061495, 0.00052388, 0.00050295,\n",
              "        0.00066815, 0.0004407 , 0.00064003, 0.00044744, 0.00050926]),\n",
              " 'std_test_score': array([0.00575249, 0.00529915, 0.00375449, 0.002052  , 0.00398265,\n",
              "        0.00315173, 0.00337454, 0.00340336, 0.00319864, 0.00301394])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joPl0mZXSPAG"
      },
      "source": [
        "### Grid search에 의한 초모수 결정 (SVM) ###\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "\r\n",
        "preproc = Pipeline([('tfidf',TfidfVectorizer(ngram_range = ngram,min_df = 5, max_df=0.6,lowercase = True)),('to_dense', DenseTransformer()),\r\n",
        "                      ('selec',SelectKBest(k=1000,score_func=chi2))])\r\n",
        "X_train1=preproc.fit_transform(X_train,y_train)\r\n",
        "X_test1=preproc.transform(X_test)\r\n",
        "\r\n",
        "param_grid = {'reg_alpha':[0,0.01],\r\n",
        "'reg_alpha':[0,0.01],\r\n",
        "'n_estimators': [100,200,500,1000],\r\n",
        "'max_depth': [50,100],\r\n",
        "'num_leaves': [30,60,100],\r\n",
        "'min_data_in_leaf':[10,20]}\r\n",
        "\r\n",
        "\r\n",
        "text_clf=lgb.LGBMClassifier(random_state=0,silent=True, verbose_eval=50)\r\n",
        "\r\n",
        "gs = GridSearchCV(estimator=text_clf, param_grid=param_grid,\r\n",
        "                scoring='accuracy', cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0))\r\n",
        "gs = gs.fit(X_train1, y_train)\r\n",
        "print(gs.best_score_)\r\n",
        "print(gs.best_params_)\r\n",
        "\r\n",
        "clf = gs.best_estimator_\r\n",
        "clf.fit(X_train1, y_train)\r\n",
        "#print(clf.score(X_train1,y_train))\r\n",
        "print('Model Training Accuracy w/o CV: %.3f' % clf.score(X_train1, y_train))\r\n",
        "print('Model Test Accuracy w/o CV: %.3f' % clf.score(X_test1, y_test))\r\n",
        "pd.DataFrame(gs.cv_results_)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm1vWnGq-isN"
      },
      "source": [
        "### Grid search에 의한 초모수 결정 (SVM) ###\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.svm import SVC\r\n",
        "\r\n",
        "preproc = Pipeline([('tfidf',TfidfVectorizer(ngram_range = ngram,min_df = 5, max_df=0.6,lowercase = True)),('to_dense', DenseTransformer()),\r\n",
        "                      ('selec',SelectKBest(k=1000,score_func=chi2))])\r\n",
        "X_train1=preproc.fit_transform(X_train,y_train)\r\n",
        "X_test1=preproc.transform(X_test)\r\n",
        "\r\n",
        "param_range = [ 0.01, 0.1, 1.0, 10.0, 100.0]\r\n",
        "param_grid = [{'C': param_range, 'loss' :[ 'hinge','squared_hinge']}]\r\n",
        "text_clf=LinearSVC(random_state=0, max_iter=5000)\r\n",
        "gs = GridSearchCV(estimator=text_clf, param_grid=param_grid,\r\n",
        "                scoring='accuracy', cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0))\r\n",
        "gs = gs.fit(X_train1, y_train)\r\n",
        "print(gs.best_score_)\r\n",
        "print(gs.best_params_)\r\n",
        "\r\n",
        "clf = gs.best_estimator_\r\n",
        "clf.fit(X_train1, y_train)\r\n",
        "#print(clf.score(X_train1,y_train))\r\n",
        "print('Model Training Accuracy w/o CV: %.3f' % clf.score(X_train1, y_train))\r\n",
        "print('Model Test Accuracy w/o CV: %.3f' % clf.score(X_test1, y_test))\r\n",
        "\r\n",
        "pd.DataFrame(gs.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gS98Jm3RByg"
      },
      "source": [
        "### Grid search에 의한 초모수 결정 (SVM) ###\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.svm import SVC\r\n",
        "\r\n",
        "preproc = Pipeline([('tfidf',TfidfVectorizer(ngram_range = ngram,min_df = 5, max_df=0.6,lowercase = True)),('to_dense', DenseTransformer()),\r\n",
        "                      ('selec',SelectKBest(k=1000,score_func=chi2))])\r\n",
        "X_train1=preproc.fit_transform(X_train,y_train)\r\n",
        "X_test1=preproc.transform(X_test)\r\n",
        "\r\n",
        "param_range = [ 0.01, 0.1, 1.0, 10.0, 100.0]\r\n",
        "param_grid = [{'C': param_range, 'loss' :[ 'squared_hinge']}]\r\n",
        "text_clf=LinearSVC(random_state=0, max_iter=5000)\r\n",
        "gs = GridSearchCV(estimator=text_clf, param_grid=param_grid,\r\n",
        "                scoring='accuracy', cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0))\r\n",
        "gs = gs.fit(X_train1, y_train)\r\n",
        "print(gs.best_score_)\r\n",
        "print(gs.best_params_)\r\n",
        "\r\n",
        "clf = gs.best_estimator_\r\n",
        "clf.fit(X_train1, y_train)\r\n",
        "#print(clf.score(X_train1,y_train))\r\n",
        "print('Model Training Accuracy w/o CV: %.3f' % clf.score(X_train1, y_train))\r\n",
        "print('Model Test Accuracy w/o CV: %.3f' % clf.score(X_test1, y_test))\r\n",
        "\r\n",
        "pd.DataFrame(gs.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qRCjl6SQlJJ"
      },
      "source": [
        "preproc = Pipeline([('tfidf',TfidfVectorizer(ngram_range = ngram,min_df = 5, max_df=0.6,lowercase = True)),('to_dense', DenseTransformer()),\r\n",
        "                      ('selec',SelectKBest(k=1000,score_func=chi2))])\r\n",
        "X_train1=preproc.fit_transform(X_train,y_train)\r\n",
        "X_val1=preproc.transform(X_val)\r\n",
        "train_dataset=Pool(data=X_train1, label=y_train)\r\n",
        "eval_dataset=Pool(data=X_val1, label=y_val)\r\n",
        "\r\n",
        "cat_cl=CatBoostClassifier(random_seed=0, max_depth=i, logging_level='Silent')\r\n",
        "gs = GridSearchCV(estimator=cat_cl, param_grid=param_grid,\r\n",
        "                scoring='accuracy', cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0))\r\n",
        "gs = gs.fit(X_train1, y_train)\r\n",
        "print(gs.best_score_)\r\n",
        "print(gs.best_params_)\r\n",
        "\r\n",
        "\r\n",
        "clf = gs.best_estimator_\r\n",
        "clf.fit(train_dataset,use_best_model=True)\r\n",
        "#print(clf.score(X_train1,y_train))\r\n",
        "print('Model Training Accuracy w/o CV: %.3f' % clf.score(train_dataset))\r\n",
        "print('Model Test Accuracy w/o CV: %.3f' % clf.score(eval_dataset))\r\n",
        "pd.DataFrame(gs.cv_results_)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWOLXwVicivu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEb_46COci3q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}